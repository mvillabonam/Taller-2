load("~/UniAndes/Big data y Machine Learning/Repositorios/Taller-2/Taller2.RData")
dataset <- train_hogares |>
left_join(train_personas, by = c("id", "Clase", "Dominio", "Fex_c", "Fex_dpto", "Depto"))
pacman::p_load(tidyverse, data.table, ggplot2, mice)
pacman::p_load(tidyverse, data.table, ggplot2, mice)
dataset |>
mutate_all(as.factor) |>
summary()
dataset <- train_hogares |>
left_join(train_personas, by = c("id", "Clase", "Dominio", "Fex_c", "Fex_dpto", "Depto"))
# ----> Dependency ratio
dataset <- dataset %>%
left_join(dataset %>% group_by(id) %>% summarise(
ocupados = sum(Oc, na.rm = TRUE),
desocupados = sum(Des, na.rm = TRUE),
inactivos = sum(Ina, na.rm = TRUE)
), by = "id") %>%
mutate(tasa_dependencia = ifelse(ocupados > 0, inactivos + desocupados / ocupados, NA))
# ----> Dependency ratio
dataset <- dataset %>%
left_join(df %>% group_by(id) %>% summarise(
ocupados = sum(Oc, na.rm = TRUE),
dependientes = sum(Ina + Des + (Pet == 0), na.rm = TRUE)
), by = "ID_hogar") %>%
mutate(tasa_dependencia = ifelse(ocupados > 0, dependientes / ocupados, NA))
# ----> Dependency ratio
dataset <- dataset %>%
left_join(df %>% group_by(id) %>% summarise(
ocupados = sum(Oc, na.rm = TRUE),
dependientes = sum(Ina + Des + (Pet == 0), na.rm = TRUE)
), by = "id") %>%
mutate(tasa_dependencia = ifelse(ocupados > 0, dependientes / ocupados, NA))
# ----> Dependency ratio
dataset <- dataset %>%
left_join(dataset %>% group_by(id) %>% summarise(
ocupados = sum(Oc, na.rm = TRUE),
dependientes = sum(Ina + Des + (Pet == 0), na.rm = TRUE)
), by = "id") %>%
mutate(tasa_dependencia = ifelse(ocupados > 0, dependientes / ocupados, NA))
# ----> Dependency ratio
dataset <- dataset %>%
left_join(dataset %>% group_by(id) %>% summarise(
ocupados = sum(Oc, na.rm = TRUE),
dependientes = sum(Ina + Des + (Pet == 0), na.rm = TRUE)
), by = "id") %>%
mutate(tasa_dependencia = ifelse(ocupados > 0, dependientes / ocupados, NA))
# ----> Dependency ratio
head(dataset)
glimpse(dataset)
dataset <- dataset %>%
group_by(id) %>%
summarise(
ocupados = sum(Oc, na.rm = TRUE),
dependientes = sum(Ina + Des + (Pet == 0), na.rm = TRUE)
)
# ----> Dependency ratio
head(dataset)
dataset <- train_hogares |>
left_join(train_personas, by = c("id", "Clase", "Dominio", "Fex_c", "Fex_dpto", "Depto"))
dataset <- dataset %>%
left_join(
dataset %>%
group_by(id) %>%
summarise(
ocupados = sum(Oc, na.rm = TRUE),
dependientes = sum(Ina, na.rm = TRUE) +
sum(Des, na.rm = TRUE) +
sum(ifelse(Pet == 0, 1, 0), na.rm = TRUE)
),
by = "id"
) %>%
mutate(tasa_dependencia = ifelse(ocupados > 0, dependientes / ocupados, NA))
# ----> Dependency ratio
head(dataset)
max_tasa <- max(dataset$tasa_dependencia, na.rm = TRUE)
print(max_tasa)
print(paste("Cantidad de NA en tasa_dependencia:", cantidad_na))
cantidad_na <- sum(is.na(dataset$tasa_dependencia))
print(paste("Cantidad de NA en tasa_dependencia:", cantidad_na))
# ----> Dependency ratio
dataset <- dataset %>%
mutate(sin_ocupados = ifelse(ocupados == 0 | is.na(ocupados), 1, 0))
glimpse(dataset)  # Revisa que la nueva variable aparece correctamente
cantidad_na <- sum(is.na(dataset$tasa_dependencia))
print(cantidad_na)
mediana_tasa <- median(dataset$tasa_dependencia, na.rm = TRUE)
print(mediana_tasa)
# ----> Average Household Education Level
household_data <- dataset %>%
group_by(id_hogar) %>%
summarise(average_education = mean(P6210, na.rm = TRUE))
# ----> Average Household Education Level
household_data <- dataset %>%
group_by(id) %>%
summarise(average_education = mean(P6210, na.rm = TRUE))
# ----> Average Household Education Level
household_data <- dataset %>%
group_by(id) %>%
summarise(average_education = mean(P6210, na.rm = TRUE)) %>%
count(is.na(average_education))
na_count <- sum(is.na(household_data$average_education))
print(paste("Number of NA values in average_education:", na_count))
hist(dataset$average_education)
# ----> Average Household Education Level
dataset<- dataset %>%
group_by(id) %>%
summarise(average_education = mean(P6210, na.rm = TRUE))
hist(dataset$average_education)
na_count <- sum(is.na(dataset$average_education))
na_count
View(dataset)
# ----> Average Household Education Level
dataset <- dataset %>%
group_by(id_hogar) %>%
mutate(health_insurance_coverage = mean(P6090 == 1, na.rm = TRUE)) %>%
ungroup()
# ----> Average Household Education Level
dataset <- dataset %>%
group_by(id) %>%
mutate(health_insurance_coverage = mean(P6090 == 1, na.rm = TRUE)) %>%
ungroup()
hist(dataset$health_insurance_coverage, col = "lightgreen")
hist(dataset$health_insurance_coverage)
dataset <- train_hogares |>
left_join(train_personas, by = c("id", "Clase", "Dominio", "Fex_c", "Fex_dpto", "Depto"))
# ----> Average Household Education Level
dataset <- dataset %>%
group_by(id) %>%
mutate(average_education = mean(P6210, na.rm = TRUE))
# ----> Average Household Education Level
dataset <- dataset %>%
group_by(id) %>%
mutate(average_education = mean(P6210, na.rm = TRUE))
na_count <- sum(is.na(dataset$average_education))
hist(dataset$average_education)
# ----> Household Health Insurance
dataset <- dataset %>%
group_by(id) %>%
mutate(health_insurance_coverage = mean(P6090 == 1, na.rm = TRUE)) %>%
ungroup()
hist(dataset$health_insurance_coverage, col = "lightgreen")
na_count <- sum(is.na(dataset$average_education))
sum(is.na(dataset$average_education))
boxplot(dataset$health_insurance_coverage, main = "Boxplot Cobertura Salud")
boxplot(dataset$average_education, main = "Boxplot Educación Promedio")
hist(dataset$health_insurance_coverage, col = "lightgreen")
dataset <- train_hogares |>
left_join(train_personas, by = c("id", "Clase", "Dominio", "Fex_c", "Fex_dpto", "Depto"))
#### Step 2: Feature Engineering ####
# ----> Overcrowding (Hacinamiento)
dataset <- dataset %>%
mutate(hacinamiento = Nper / P5010)
# household costs by tenure type (P5090)
dataset %>%
group_by(P5090) %>%
summarise(
pays_amortization = sum(!is.na(P5100)),
pays_rent = sum(!is.na(P5140)),
pays_imputed_rent = sum(!is.na(P5130)),
total_people = n()
)
summary(dataset$costo_vivienda)
load("~/UniAndes/Big data y Machine Learning/Repositorios/Taller-2/Taller2.RData")
pacman::p_load(tidyverse, data.table, ggplot2, mice)
dataset <- train_hogares |>
left_join(train_personas, by = c("id", "Clase", "Dominio", "Fex_c", "Fex_dpto", "Depto"))
#### Step 2: Feature Engineering ####
# ----> Overcrowding (Hacinamiento)
dataset <- dataset |>
mutate(hacinamiento = Nper / P5010)
head(dataset)
sum(is.na(dataset$hacinamiento))
sum(is.na(dataset$costo_vivienda))
# ----> Dependency ratio
dataset <- dataset |>
group_by(id) |>
mutate(
ocupados = sum(Oc, na.rm = TRUE),
dependientes = sum(Ina, na.rm = TRUE) +
sum(Des, na.rm = TRUE) +
sum(ifelse(Pet == 0, 1, 0), na.rm = TRUE),
tasa_dependencia = ifelse(ocupados > 0, dependientes / ocupados, NA)
) |>
ungroup()
#Revisando si es viable imputar los NA
max_tasa <- max(dataset$tasa_dependencia, na.rm = TRUE)
print(max_tasa)
#Revisando si es viable imputar los NA
max(dataset$tasa_dependencia, na.rm = TRUE)
#Revisando si es viable imputar los NA
sum(is.na(dataset$tasa_dependencia))
head(dataset)
dataset <- dataset |>
group_by(id) |>
mutate(
ocupados = sum(Oc, na.rm = TRUE),
dependientes = sum(Ina, na.rm = TRUE) +
sum(Des, na.rm = TRUE) +
sum(ifelse(is.na(Pet), 1, 0), na.rm = TRUE),  # Cambio clave aquí
tasa_dependencia = ifelse(ocupados > 0, dependientes / ocupados, NA)
) |>
ungroup()
dataset <- dataset |>
group_by(id) |>
mutate(
ocupados = sum(Oc, na.rm = TRUE),
dependientes = sum(Ina, na.rm = TRUE) +
sum(Des, na.rm = TRUE) +
sum(ifelse(is.na(Pet), 1, 0), na.rm = TRUE),  # Cambio clave aquí
tasa_dependencia = ifelse(ocupados > 0, dependientes / ocupados, NA)
) |>
ungroup()
head(dataset)
# Calculate the sum without adding it to the dataset
suma_ocupados_dependientes <- dataset$ocupados + dataset$dependientes
# Compare with Nper
coincide_con_Nper <- suma_ocupados_dependientes == dataset$Nper
# Count matches
table(coincide_con_Nper)
table((dataset$ocupados + dataset$dependientes) == dataset$Nper)
#Revisando si es viable imputar los NA
sum(is.na(dataset$tasa_dependencia))
#Revisando si es viable imputar los NA
sum(is.na(dataset$tasa_dependencia))
max(dataset$tasa_dependencia, na.rm = TRUE)
median(dataset$tasa_dependencia, na.rm = TRUE)
head(dataset)
# ----> Household education level
dataset <- dataset |>
group_by(id) |>
mutate(
educacion_promedio_ = median(P6210, na.rm = TRUE),
max_educ_hogar = max(P6210, na.rm = TRUE)
) |>
ungroup()
# ----> Household education level
dataset <- dataset |>
group_by(id) |>
mutate(
educacion_promedio_ = median(P6210, na.rm = TRUE),
max_educ_hogar = max(P6210, na.rm = TRUE)
) |>
ungroup()
head(dataset)
# ----> Household education level
dataset <- dataset |>
group_by(id) |>
mutate(
educacion_hogar = median(P6210, na.rm = TRUE),
max_educ_hogar = max(P6210, na.rm = TRUE)
) |>
ungroup()
# ----> Household education level
dataset <- dataset |>
group_by(id) |>
mutate(
educacion_hogar = median(P6210, na.rm = TRUE),
max_educ_hogar = max(P6210, na.rm = TRUE)
) |>
ungroup()
sum(is.na(dataset$median_education))
# ----> Household education level
dataset <- dataset |>
group_by(id) |>
mutate(
median_education = median(P6210, na.rm = TRUE),
max_educ_hogar = max(P6210, na.rm = TRUE)
) |>
ungroup()
# ----> Household education level
dataset <- dataset |>
group_by(id) |>
mutate(
median_education = median(P6210, na.rm = TRUE),
max_educ_hogar = max(P6210, na.rm = TRUE)
) |>
ungroup()
head(dataset)
sum(is.na(dataset$median_education))
sum(is.na(dataset$max_educ_hogar))
hist(dataset$median_education)
hist(dataset$max_educ_hogar)
# ----> Household health security
dataset <- dataset |>
group_by(id) |>
mutate(health_insurance_coverage = mean(P6090 == 1, na.rm = TRUE)) |>
ungroup()
sum(is.na(dataset$average_education))
# ----> Household health security
dataset <- dataset |>
group_by(id) |>
mutate(health = mean(P6090 == 1, na.rm = TRUE)) |>
ungroup()
sum(is.na(dataset$health))
sum(is.na(dataset$health))
load("~/UniAndes/Big data y Machine Learning/Repositorios/Taller-2/Taller2.RData")
table((dataset$ocupados + dataset$dependientes) == dataset$Nper)
dataset <- train_hogares |>
left_join(train_personas, by = c("id", "Clase", "Dominio", "Fex_c", "Fex_dpto", "Depto"))
pacman::p_load(tidyverse, data.table, ggplot2, mice)
dataset <- train_hogares |>
left_join(train_personas, by = c("id", "Clase", "Dominio", "Fex_c", "Fex_dpto", "Depto"))
dataset_test<- test_hogares |>
left_join(test_personas, by = c("id", "Clase", "Dominio", "Fex_c", "Fex_dpto", "Depto"))
pacman::p_load(tidyverse, data.table, ggplot2, mice)
knitr::opts_chunk$set(echo = TRUE)
require(pacman)
p_load(
readxl,         # Read excel files
tidyverse,      # Tidy data
skimr,          # Data summary
ranger,
caret,         # Entrenamiento y evaluacion de modelos
doParallel,     # Paralelizacion
MLeval,         # Funciones para evaluar modelos con métricas gráficos.
#MLmetrics,     # Colección de métricas de evaluación para modelos de machine learning.
pROC,
adabag
)
adagrid <- expand.grid(
mfinal = c(50),             # solo un valor
maxdepth = c(1, 2),         # dos valores
coeflearn = c("Breiman")    # un método
)
adaboost_model <- train(
Pobre ~ tasa_dependencia + Nper + median_education + hacinamiento +
costo_vivienda + vulnerabilidad + edad_jefe,
data = train_dataset,
method = "AdaBoost.M1",  # AdaBoost.M1 algorithm
trControl = ctrl,
metric = "ROC",
tuneGrid = adagrid
)
p_load(
readxl,         # Read excel files
tidyverse,      # Tidy data
skimr,          # Data summary
ranger,
caret,         # Entrenamiento y evaluacion de modelos
doParallel,     # Paralelizacion
MLeval,         # Funciones para evaluar modelos con métricas gráficos.
#MLmetrics,     # Colección de métricas de evaluación para modelos de machine learning.
pROC,
adabag
)
train_dataset <- read_xlsx("train_dataset.xlsx")
train_dataset <- read_xlsx("train_dataset.xlsx")
