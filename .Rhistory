knitr::opts_chunk$set(echo = TRUE)
require(pacman)
p_load(
readxl,         # Read excel files
tidyverse,      # Tidy data
skimr,          # Data summary
ranger,
caret,         # Entrenamiento y evaluacion de modelos
doParallel,     # Paralelizacion
MLeval,         # Funciones para evaluar modelos con métricas gráficos.
MLmetrics,     # Colección de métricas de evaluación para modelos de machine learning.
pROC,
adabag,
e1071,
ranger,         # Para bagging y random forest
randomForest,   # Para random forest
Metrics,        # Evaluation Metrics for ML
adabag,
gbm,            # Gradient Boosting
xgboost,        # XGBoosting
pROC,           # ROC curve
ParBayesianOptimization, # Selecting parameters on XGBoost
doParallel,     # Paralellize data proccessing
)
train_dataset <- read_xlsx("train_dataset.xlsx")
test_dataset <- read_xlsx("test_dataset.xlsx")
# Pobre as a factor
train_dataset <- train_dataset %>%
mutate(Pobre = factor(Pobre, levels = c(1, 0), labels = c("Pobre", "No_pobre")))
knitr::opts_chunk$set(echo = TRUE)
require(pacman)
p_load(
readxl,         # Read excel files
tidyverse,      # Tidy data
skimr,          # Data summary
ranger,
caret,         # Entrenamiento y evaluacion de modelos
doParallel,     # Paralelizacion
MLeval,         # Funciones para evaluar modelos con métricas gráficos.
MLmetrics,     # Colección de métricas de evaluación para modelos de machine learning.
pROC,
adabag,
e1071,
ranger,         # Para bagging y random forest
randomForest,   # Para random forest
Metrics,        # Evaluation Metrics for ML
adabag,
gbm,            # Gradient Boosting
xgboost,        # XGBoosting
pROC,           # ROC curve
ParBayesianOptimization, # Selecting parameters on XGBoost
doParallel,     # Paralellize data proccessing
)
train_dataset <- read_xlsx("train_dataset.xlsx")
test_dataset <- read_xlsx("test_dataset.xlsx")
# Pobre as a factor
train_dataset <- train_dataset %>%
mutate(Pobre = factor(Pobre, levels = c(1, 0), labels = c("Pobre", "No_pobre")))
skim(train_dataset)
skim(test_dataset)
train_dataset <- train_dataset |>
mutate(actividad_jefe = ifelse(is.na(actividad_jefe),"6", actividad_jefe))
test_dataset <- test_dataset |>
mutate(actividad_jefe = ifelse(is.na(actividad_jefe),"6", actividad_jefe))
ggplot(train_dataset, aes(x = Pobre, fill = Pobre)) +
geom_bar() +
theme_minimal() +
scale_fill_manual(values = c("Pobre" = "orange", "No_pobre"= "blue")) +
labs(x = "", y = "# de Personas")
multiStats <- function(...) c(twoClassSummary(...), defaultSummary(...), prSummary(...), multiClassSummary(...))
# ESTABLECIENDO EL CONTROL ---> PERMITIENDO PARALELIZACIÓN DE NÚCLEOS
num_cores <- parallel::detectCores() - 1
cl <- makeCluster(num_cores)
registerDoParallel(cl)
ctrl <- trainControl(
method = "cv",
number = 5,
classProbs = TRUE,
summaryFunction = multiStats,
verboseIter = TRUE,
allowParallel = TRUE
)
multiStats <- function(...) c(twoClassSummary(...), defaultSummary(...), prSummary(...), multiClassSummary(...))
# ESTABLECIENDO EL CONTROL ---> PERMITIENDO PARALELIZACIÓN DE NÚCLEOS
num_cores <- parallel::detectCores() - 2
cl <- makeCluster(num_cores)
registerDoParallel(cl)
ctrl <- trainControl(
method = "cv",
number = 5,
classProbs = TRUE,
summaryFunction = multiStats,
verboseIter = TRUE,
allowParallel = TRUE
)
# Entrenar con glm binomial
set.seed(1231)
x_variables <- c(colnames(train_dataset)[-c(1,3,8,9,10,11,13,14)])
glm_caret <- train(formula(paste0("Pobre ~", paste0(x_variables, collapse = " + "))),
data = train_dataset,
method = "glm",
trControl = ctrl,
family = "binomial")
knitr::opts_chunk$set(echo = TRUE)
require(pacman)
p_load(
readxl,         # Read excel files
tidyverse,      # Tidy data
skimr,          # Data summary
caret,          # Entrenamiento y evaluacion de modelos
doParallel,     # Paralelizacion
MLeval,         # Funciones para evaluar modelos con métricas gráficos.
#MLmetrics,     # Colección de métricas de evaluación para modelos de machine learning.
pROC,
rpart,
rpart.plot,
gbm
)
train_dataset <- readRDS("train_dataset.rds")
test_dataset <- readRDS("test_dataset.rds")
train_dataset <- train_dataset |>
mutate(Pobre = factor(Pobre, levels = c(1, 0), labels = c("Pobre", "No_pobre")))
train_dataset |> summary()
skim(train_dataset)
skim(test_dataset)
train_dataset$actividad_jefe[is.na(train_dataset$actividad_jefe)] <- 6
test_dataset$num_ocupados[is.na(test_dataset$num_ocupados)] <- "mas_de_8"
test_dataset$actividad_jefe[is.na(test_dataset$actividad_jefe)] <- 6
ggplot(train_dataset, aes(x = Pobre, fill = Pobre)) +
geom_bar() +
theme_minimal() +
scale_fill_manual(values = c("Pobre" = "orange", "No_pobre"= "blue")) +
labs(x = "", y = "# de Personas")
library(pacman)
pacman::p_load(
tidyverse, dyplr, ggplot2, openxlsx
)
train_hogares <- read_csv("train_hogares.csv")
train_personas <- readRDS("train_personas.rds")
test_hogares <- read_csv("test_hogares.csv")
test_personas <- read_csv("test_personas.csv")
#-2. MERGE in train dataset ------------------------------------
train_hogares <- train_hogares |>
select(colnames(test_hogares), Pobre)
train_personas <- train_personas |>
select(colnames(test_personas))
train_dataset |>
select(starts_with("P")) |>
mutate_all(as.factor) |>
summary()
# ----> 1. EXPLORING DATA SET  ----
# MAIN STATISTICS
summary <- train_dataset |>
select(where(is.numeric)) |>
pivot_longer(everything(), names_to = "Variable", values_to = "Value") |>
group_by(Variable) |>
summarise(
Min = round(min(Value, na.rm = TRUE),2),
Mean = round(mean(Value, na.rm = TRUE),2),
Max = round(max(Value, na.rm = TRUE),2),
NA_count = sum(is.na(Value)),
NA_percent = round(100 * mean(is.na(Value)), 2)
)
# ----> 1. EXPLORING DATA SET  ----
# MAIN STATISTICS
summary <- train_dataset |>
select(where(is.numeric)) |>
pivot_longer(everything(), names_to = "Variable", values_to = "Value") |>
group_by(Variable) |>
summarise(
Min = round(min(Value, na.rm = TRUE),2),
Mean = round(mean(Value, na.rm = TRUE),2),
Max = round(max(Value, na.rm = TRUE),2),
NA_count = sum(is.na(Value)),
NA_percent = round(100 * mean(is.na(Value)), 2)
)
sum(train_dataset$Fex_c
sum(train_dataset$Fex_c)
sum(train_dataset$Fex_c)
sum(train_personas$Fex_c)
# ----> P6090 y P6100:
SEGURIDAD_SOCIAL <- train_dataset|>
group_by(P6090, P6100,age_group) |>
summarise(count = n(), .groups = "drop_last") |>
mutate(total = sum(count)) |>
mutate(porcentaje = count / total)
#-----------ESTABLECER DIRECTORIO--------------------------
# setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# 1. Cargar los datos ----
train_hogares <- read_csv("train_hogares.csv")
train_personas <- readRDS("train_personas.rds")
test_hogares <- read_csv("test_hogares.csv")
test_personas <- read_csv("test_personas.csv")
# > TRAIN DATA SET -------
#-2. MERGE in train dataset ------------------------------------
train_hogares <- train_hogares |>
select(colnames(test_hogares), Pobre)
train_personas <- train_personas |>
select(colnames(test_personas))
train_dataset <- train_hogares |>
left_join(train_personas, by = c("id", "Clase", "Dominio", "Fex_c", "Fex_dpto", "Depto"))
# ----> 1. EXPLORING DATA SET
train_dataset |>
select(starts_with("P")) |>
mutate_all(as.factor) |>
summary()
# ---------------------- DATA DESCRIPTIVE STATISTICS----------------------------
# ----> 1. EXPLORING DATA SET  ----
# MAIN STATISTICS
summary <- train_dataset |>
select(where(is.numeric)) |>
pivot_longer(everything(), names_to = "Variable", values_to = "Value") |>
group_by(Variable) |>
summarise(
Min = round(min(Value, na.rm = TRUE),2),
Mean = round(mean(Value, na.rm = TRUE),2),
Max = round(max(Value, na.rm = TRUE),2),
NA_count = sum(is.na(Value)),
NA_percent = round(100 * mean(is.na(Value)), 2)
)
write_csv(summary, "2.Exploracion.csv")
# ----> CREATE GROUP AGES
train_dataset <- train_dataset |>
mutate(age_group = case_when(
P6040 < 12 ~ "0-12",
P6040 >= 12 & P6040 < 18 ~ "12-18",
P6040 >= 18 & P6040 < 24 ~ "18-24",
P6040 >= 24 & P6040 < 65 ~ "24-65",
P6040 >= 65 ~ "65+"
)) |>
mutate(age_group = factor(age_group,
levels = c("0-12", "12-18", "18-24", "24-65", "65+"),
ordered = TRUE))
# ----> P6090 y P6100:
SEGURIDAD_SOCIAL <- train_dataset|>
group_by(P6090, P6100,age_group) |>
summarise(count = n(), .groups = "drop_last") |>
mutate(total = sum(count)) |>
mutate(porcentaje = count / total)
SEGURIDAD_SOCIAL
# ---> INFORMAL WORKER
JOB_TYPE <- train_dataset |>
group_by(age_group, P6430) |>
summarise(count = sum(is.na(P6430)), .groups = "drop_last") |>
ungroup() |>
mutate(total = sum(count)) |>
mutate(porcentaje = round(count / total, 2))
#rm(JOB_TYPE)
JOB_TYPE
JOB_TYPE <- train_dataset |>
group_by(age_group) |>
summarise(
na_count = sum(is.na(P6430)),
total_count = n(),
porcentaje = round(na_count / total_count, 2),
.groups = "drop"
)
JOB_TYPE
# ---> INFORMAL WORKER
JOB_TYPE <- train_dataset |>
group_by(age_group, P6430) |>
summarise(count = sum(is.na(P6430)), .groups = "drop_last") |>
ungroup() |>
mutate(total = sum(count)) |>
mutate(porcentaje = round(count / total, 2))
)
JOB_TYPE
View(JOB_TYPE)
JOB_TYPE_NA_ <- train_dataset |>
group_by(age_group) |>
summarise(
na_count = sum(is.na(P6430)),
total_count = n(),
porcentaje = round(na_count / total_count, 2),
.groups = "drop"
)
JOB_TYPE_NA_
# ---> INFORMAL WORKER
JOB_TYPE_NA_ <- train_dataset |>
group_by(age_group) |>
summarise(
na_count = sum(is.na(P6430)),
.groups = "drop"
) |>
mutate(
total_na = sum(na_count),
porcentaje = round(na_count / total_na * 100, 2)
)
JOB_TYPE_NA_
# ----> CREATE GROUP AGES FOR ANALYSIS OF MISSING VALUES
train_dataset <- train_dataset |>
mutate(age_group = case_when(
P6040 < 12 ~ "0-12",
P6040 >= 12 & P6040 < 18 ~ "12-18",
P6040 >= 18 & P6040 < 24 ~ "18-24",
P6040 >= 24 & P6040 < 65 ~ "24-65",
P6040 >= 65 ~ "65+"
)) |>
mutate(age_group = factor(age_group,
levels = c("0-12", "12-18", "18-24", "24-65", "65+"),
ordered = TRUE))
# ----> P6090 y P6100:
SEGURIDAD_SOCIAL <- train_dataset|>
group_by(P6090, P6100,age_group) |>
summarise(count = n(), .groups = "drop_last") |>
mutate(total = sum(count)) |>
mutate(porcentaje = count / total)
SEGURIDAD_SOCIAL
kable(JOB_TYPE_NA_, format = "latex", digits = 2, caption = "Distribution of Missing Job Type (P6430) by Age Group")
library(pacman)
pacman::p_load(
tidyverse, dyplr, ggplot2, openxlsx,knitr
)
#-----------ESTABLECER DIRECTORIO--------------------------
# setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# 1. Cargar los datos ----
train_hogares <- read_csv("train_hogares.csv")
train_personas <- readRDS("train_personas.rds")
test_hogares <- read_csv("test_hogares.csv")
test_personas <- read_csv("test_personas.csv")
# > TRAIN DATA SET -------
#-2. MERGE in train dataset ------------------------------------
train_hogares <- train_hogares |>
select(colnames(test_hogares), Pobre)
train_personas <- train_personas |>
select(colnames(test_personas))
train_dataset <- train_hogares |>
left_join(train_personas, by = c("id", "Clase", "Dominio", "Fex_c", "Fex_dpto", "Depto"))
# ----> 1. EXPLORING DATA SET
train_dataset |>
select(starts_with("P")) |>
mutate_all(as.factor) |>
summary()
# ---------------------- DATA DESCRIPTIVE STATISTICS----------------------------
# ----> 1. EXPLORING DATA SET  ----
# MAIN STATISTICS
summary <- train_dataset |>
select(where(is.numeric)) |>
pivot_longer(everything(), names_to = "Variable", values_to = "Value") |>
group_by(Variable) |>
summarise(
Min = round(min(Value, na.rm = TRUE),2),
Mean = round(mean(Value, na.rm = TRUE),2),
Max = round(max(Value, na.rm = TRUE),2),
NA_count = sum(is.na(Value)),
NA_percent = round(100 * mean(is.na(Value)), 2)
)
write_csv(summary, "2.Exploracion.csv")
# ----> CREATE GROUP AGES FOR ANALYSIS OF MISSING VALUES
train_dataset <- train_dataset |>
mutate(age_group = case_when(
P6040 < 12 ~ "0-12",
P6040 >= 12 & P6040 < 18 ~ "12-18",
P6040 >= 18 & P6040 < 24 ~ "18-24",
P6040 >= 24 & P6040 < 65 ~ "24-65",
P6040 >= 65 ~ "65+"
)) |>
mutate(age_group = factor(age_group,
levels = c("0-12", "12-18", "18-24", "24-65", "65+"),
ordered = TRUE))
# ----> P6090 y P6100:
SEGURIDAD_SOCIAL <- train_dataset|>
group_by(P6090, P6100,age_group) |>
summarise(count = n(), .groups = "drop_last") |>
mutate(total = sum(count)) |>
mutate(porcentaje = count / total)
SEGURIDAD_SOCIAL
# ---> CREATING NEW VARIABLES.
# ---> PERTENECE AL RÉGIMEN SUBSIDIADO?
train_dataset <- train_dataset |>
mutate(regimen_subsidiado = as.numeric(case_when(P6100 == 3 ~ 1, TRUE ~ 0))) ;rm(SEGURIDAD_SOCIAL)
# ---> INFORMAL WORKER
JOB_TYPE_NA_ <- train_dataset |>
group_by(age_group) |>
summarise(
na_count = sum(is.na(P6430)),
.groups = "drop"
) |>
mutate(
total_na = sum(na_count),
porcentaje = round(na_count / total_na * 100, 2)
)
kable(JOB_TYPE_NA_, format = "latex", digits = 2, caption = "Distribution of Missing Job Type (P6430) by Age Group")
JOB_TYPE <- train_dataset |>
group_by(age_group, P6430) |>
summarise(count = sum(is.na(P6430)), .groups = "drop_last") |>
ungroup() |>
mutate(total = sum(count)) |>
mutate(porcentaje = round(count / total, 2))
JOB_TYPE <- train_dataset |>
group_by(age_group, P6430) |>
summarise(count = sum(is.na(P6430)), .groups = "drop_last") |>
ungroup() |>
mutate(total = sum(count)) |>
mutate(porcentaje = round(count / total, 2))
View(JOB_TYPE)
JOB_TYPE <- train_dataset |>
group_by(age_group, P6430) |>
summarise(count = sum(is.na(P6430)), .groups = "drop_last") |>
ungroup() |>
mutate(total = sum(count)) |>
mutate(porcentaje = round(count / total, 2))
View(JOB_TYPE)
JOB_TYPE <- train_dataset |>
group_by(age_group, P6430) |>
summarise(count = sum(P6430), .groups = "drop_last") |>
ungroup() |>
mutate(total = sum(count)) |>
mutate(porcentaje = round(count / total, 2))
View(JOB_TYPE)
JOB_TYPE <- train_dataset |>
group_by(age_group, P6430) |>
summarise(count = sum(is.na(P6430)), .groups = "drop_last") |>
ungroup() |>
mutate(total = sum(count)) |>
mutate(porcentaje = round(count / total, 2))
View(JOB_TYPE)
JOB_TYPE <- train_dataset |>
group_by(age_group, P6430) |>
summarise(count = sum(P6430), .groups = "drop_last") |>
ungroup() |>
mutate(total = sum(count)) |>
mutate(porcentaje = round(count / total, 2))
JOB_TYPE <- train_dataset |>
filter(!is.na(P6430)) |>
group_by(age_group, P6430) |>
summarise(count = n(), .groups = "drop") |>
ungroup() |>
mutate(total = sum(count)) |>
mutate(porcentaje = round(count / total * 100, 2))
View(JOB_TYPE)
rm(JOB_TYPE_NA_)
kable(JOB_TYPE, format = "latex", digits = 2, caption = "Distribution of Missing Job Type (P6430) by Age Group")
write_csv(JOB_TYPE, "JOB_TYPE.csv")
# ------------------------ CREATING NEW VARIABLES-------------------------------
# ---> PERTENECE AL RÉGIMEN SUBSIDIADO?
train_dataset <- train_dataset |>
mutate(regimen_subsidiado = as.numeric(case_when(P6100 == 3 ~ 1, TRUE ~ 0))) ;rm(SEGURIDAD_SOCIAL)
EDUCACION <- train_hogares %>%
group_by(P6210) %>%
summarise(count = n()) %>%
mutate(percent = round(100 * count / sum(count), 2))
View(train_hogares)
EDUCACION <- train_dataset %>%
group_by(P6210) %>%
summarise(count = n()) %>%
mutate(percent = round(100 * count / sum(count), 2))
View(EDUCACION)
plot_data <- train_hogares %>%
group_by(P6210, Ocupado) %>%
summarise(count = n(), .groups = "drop") %>%
group_by(Ocupado) %>%
mutate(percent = 100 * count / sum(count))
# --->  DESCRIPTION OF EDUCATION
EDUCATION <- train_hogares %>%
group_by(P6210, Ocupado) %>%
summarise(count = n(), .groups = "drop") %>%
group_by(Ocupado) %>%
mutate(percent = 100 * count / sum(count))
View(EDUCACION)
# --->  DESCRIPTION OF EDUCATION
EDUCATION <- train_hogares %>%
group_by(P6210, Ocupado) %>%
summarise(count = n(), .groups = "drop") %>%
group_by(Ocupado) %>%
mutate(percent = 100 * count / sum(count))
View(EDUCACION)
ggplot(plot_data, aes(x = factor(P6210), y = percent, fill = factor(Ocupado))) +
geom_bar(stat = "identity", position = "dodge") +
labs(
title = "Distribution of P6210 by Employment Status",
x = "P6210",
y = "Percentage",
fill = "Ocupado"
) +
theme_minimal()
ggplot(EDUCATION, aes(x = factor(P6210), y = percent, fill = factor(Ocupado))) +
geom_bar(stat = "identity", position = "dodge") +
labs(
title = "Distribution of P6210 by Employment Status",
x = "P6210",
y = "Percentage",
fill = "Ocupado"
) +
theme_minimal()
EDUCATION <- train_hogares %>%
group_by(P6210, Ocupado) %>%
summarise(count = n(), .groups = "drop") %>%
group_by(Ocupado) %>%
mutate(percent = 100 * count / sum(count))
# --->  DESCRIPTION OF EDUCATION
EDUCATION <- train_hogares %>%
group_by(P6210, Ocupado) %>%
summarise(count = n(), .groups = "drop") %>%
group_by(Ocupado) %>%
mutate(percent = 100 * count / sum(count))
