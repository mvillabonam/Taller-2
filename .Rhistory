knitr::opts_chunk$set(echo = TRUE)
require(pacman)
p_load(
readxl,         # Read excel files
tidyverse,      # Tidy data
skimr,          # Data summary
ranger,
caret,         # Entrenamiento y evaluacion de modelos
doParallel,     # Paralelizacion
MLeval,         # Funciones para evaluar modelos con métricas gráficos.
MLmetrics,     # Colección de métricas de evaluación para modelos de machine learning.
pROC,
adabag,
e1071,
ranger,         # Para bagging y random forest
randomForest,   # Para random forest
Metrics,        # Evaluation Metrics for ML
adabag,
gbm,            # Gradient Boosting
xgboost,        # XGBoosting
pROC,           # ROC curve
ParBayesianOptimization, # Selecting parameters on XGBoost
doParallel,     # Paralellize data proccessing
)
train_dataset <- read_xlsx("train_dataset.xlsx")
test_dataset <- read_xlsx("test_dataset.xlsx")
# Pobre as a factor
train_dataset <- train_dataset %>%
mutate(Pobre = factor(Pobre, levels = c(1, 0), labels = c("Pobre", "No_pobre")))
knitr::opts_chunk$set(echo = TRUE)
require(pacman)
p_load(
readxl,         # Read excel files
tidyverse,      # Tidy data
skimr,          # Data summary
ranger,
caret,         # Entrenamiento y evaluacion de modelos
doParallel,     # Paralelizacion
MLeval,         # Funciones para evaluar modelos con métricas gráficos.
MLmetrics,     # Colección de métricas de evaluación para modelos de machine learning.
pROC,
adabag,
e1071,
ranger,         # Para bagging y random forest
randomForest,   # Para random forest
Metrics,        # Evaluation Metrics for ML
adabag,
gbm,            # Gradient Boosting
xgboost,        # XGBoosting
pROC,           # ROC curve
ParBayesianOptimization, # Selecting parameters on XGBoost
doParallel,     # Paralellize data proccessing
)
train_dataset <- read_xlsx("train_dataset.xlsx")
test_dataset <- read_xlsx("test_dataset.xlsx")
# Pobre as a factor
train_dataset <- train_dataset %>%
mutate(Pobre = factor(Pobre, levels = c(1, 0), labels = c("Pobre", "No_pobre")))
skim(train_dataset)
skim(test_dataset)
train_dataset <- train_dataset |>
mutate(actividad_jefe = ifelse(is.na(actividad_jefe),"6", actividad_jefe))
test_dataset <- test_dataset |>
mutate(actividad_jefe = ifelse(is.na(actividad_jefe),"6", actividad_jefe))
ggplot(train_dataset, aes(x = Pobre, fill = Pobre)) +
geom_bar() +
theme_minimal() +
scale_fill_manual(values = c("Pobre" = "orange", "No_pobre"= "blue")) +
labs(x = "", y = "# de Personas")
multiStats <- function(...) c(twoClassSummary(...), defaultSummary(...), prSummary(...), multiClassSummary(...))
# ESTABLECIENDO EL CONTROL ---> PERMITIENDO PARALELIZACIÓN DE NÚCLEOS
num_cores <- parallel::detectCores() - 1
cl <- makeCluster(num_cores)
registerDoParallel(cl)
ctrl <- trainControl(
method = "cv",
number = 5,
classProbs = TRUE,
summaryFunction = multiStats,
verboseIter = TRUE,
allowParallel = TRUE
)
multiStats <- function(...) c(twoClassSummary(...), defaultSummary(...), prSummary(...), multiClassSummary(...))
# ESTABLECIENDO EL CONTROL ---> PERMITIENDO PARALELIZACIÓN DE NÚCLEOS
num_cores <- parallel::detectCores() - 2
cl <- makeCluster(num_cores)
registerDoParallel(cl)
ctrl <- trainControl(
method = "cv",
number = 5,
classProbs = TRUE,
summaryFunction = multiStats,
verboseIter = TRUE,
allowParallel = TRUE
)
# Entrenar con glm binomial
set.seed(1231)
x_variables <- c(colnames(train_dataset)[-c(1,3,8,9,10,11,13,14)])
glm_caret <- train(formula(paste0("Pobre ~", paste0(x_variables, collapse = " + "))),
data = train_dataset,
method = "glm",
trControl = ctrl,
family = "binomial")
knitr::opts_chunk$set(echo = TRUE)
require(pacman)
p_load(
readxl,         # Read excel files
tidyverse,      # Tidy data
skimr,          # Data summary
caret,          # Entrenamiento y evaluacion de modelos
doParallel,     # Paralelizacion
MLeval,         # Funciones para evaluar modelos con métricas gráficos.
#MLmetrics,     # Colección de métricas de evaluación para modelos de machine learning.
pROC,
rpart,
rpart.plot,
gbm
)
train_dataset <- readRDS("train_dataset.rds")
test_dataset <- readRDS("test_dataset.rds")
train_dataset <- train_dataset |>
mutate(Pobre = factor(Pobre, levels = c(1, 0), labels = c("Pobre", "No_pobre")))
train_dataset |> summary()
skim(train_dataset)
skim(test_dataset)
train_dataset$actividad_jefe[is.na(train_dataset$actividad_jefe)] <- 6
test_dataset$num_ocupados[is.na(test_dataset$num_ocupados)] <- "mas_de_8"
test_dataset$actividad_jefe[is.na(test_dataset$actividad_jefe)] <- 6
ggplot(train_dataset, aes(x = Pobre, fill = Pobre)) +
geom_bar() +
theme_minimal() +
scale_fill_manual(values = c("Pobre" = "orange", "No_pobre"= "blue")) +
labs(x = "", y = "# de Personas")
